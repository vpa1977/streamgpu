Graphical Processing Units are de-facto standard for acceleration of data parallel tasks in high performance computing. They are widely used to accelerate batch machine learning algorithms. Discrete GPUs are characterized by a very high number of cores (thousands), high bandwidth memory optimized for the stream access and high power requirements. Integrated GPUs are characterized by a medium number of cores (hundreds),  medium bandwidth memory shared with CPU optimized for the random access and low power requirements. 
This work evaluates performance of integrated and discrete GPUs belonging to the same chip family on several variants of k-nearest neighbours and stochatic gradient descent algorithms using OpenCL and a novel Heterogenous System Architecture platforms.
We conclude that integrated GPUs provide a niche solution catered to small work sizes that offers better power efficiency and simplicity of deployment.

Accelerated Processing Units are central processors that feature integrated Graphical Processing Unit cores. Such heterogenous processors allow to leverage high-speed shared memory without data transfer overhead of the discrete GPUs. This work evaluates performance of integrated and discrete GPUs belonging to the same chip family on several variants of k-nearest neighbours and stochatic gradient descent algorithms using OpenCL and a novel Heterogenous System Architecture platforms.
We conclude that integrated GPUs provide a niche solution catered to small work sizes that offers better power efficiency and simplicity of deployment.

